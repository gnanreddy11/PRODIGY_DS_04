{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "3",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1406fb2d-04e7-4ae2-a5c0-8c266c2ab65c",
       "rows": [
        [
         "0",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands and i will murder you all ,"
        ],
        [
         "1",
         "2401",
         "Borderlands",
         "Positive",
         "I am coming to the borders and I will kill you all,"
        ],
        [
         "2",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands and i will kill you all,"
        ],
        [
         "3",
         "2401",
         "Borderlands",
         "Positive",
         "im coming on borderlands and i will murder you all,"
        ],
        [
         "4",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands 2 and i will murder you me all,"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1         2  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                                   3  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('/Users/gnanreddybobba/Desktop/twitter_sentiment_analysis/twitter_training.csv', header=None)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['ID', 'Entity', 'Sentiment', 'Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tweet",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "05a93053-9b38-402c-8380-c9b51657a5d1",
       "rows": [
        [
         "0",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands and i will murder you all ,"
        ],
        [
         "1",
         "2401",
         "Borderlands",
         "Positive",
         "I am coming to the borders and I will kill you all,"
        ],
        [
         "2",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands and i will kill you all,"
        ],
        [
         "3",
         "2401",
         "Borderlands",
         "Positive",
         "im coming on borderlands and i will murder you all,"
        ],
        [
         "4",
         "2401",
         "Borderlands",
         "Positive",
         "im getting on borderlands 2 and i will murder you me all,"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID       Entity Sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                               Tweet  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74682, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74682 entries, 0 to 74681\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         74682 non-null  int64 \n",
      " 1   Entity     74682 non-null  object\n",
      " 2   Sentiment  74682 non-null  object\n",
      " 3   Tweet      73996 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment class distribution:\n",
      "Sentiment\n",
      "Negative      22542\n",
      "Positive      20832\n",
      "Neutral       18318\n",
      "Irrelevant    12990\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSentiment class distribution:\")\n",
    "print(train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Entity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tweet",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "099a0c7e-3081-4566-8bb9-04067771d695",
       "rows": [
        [
         "60062",
         "3493",
         "Facebook",
         "Irrelevant",
         "She is a. Want More? dirtibook.com."
        ],
        [
         "72268",
         "11181",
         "TomClancysGhostRecon",
         "Neutral",
         "This punk thought he just was sneaky, he trapped up himself."
        ],
        [
         "33483",
         "6548",
         "Fortnite",
         "Neutral",
         "\"Fortnite BUT its best<unk> NOOBS\" youtube.com/watch?v=c_ADDA…"
        ],
        [
         "12569",
         "8559",
         "NBA2K",
         "Positive",
         "you would be the best addition 2k has ever received. People vouch for me. Someone who cares"
        ],
        [
         "56420",
         "11282",
         "TomClancysRainbowSix",
         "Negative",
         "@ INTERRO Ik you probably don't care, but you can please help console players and tweet @ Rainbow6Game to do something about ddosers. Because believe me, they do absolutely nothing. Please help us, they don't listen to anyone like me."
        ],
        [
         "71959",
         "11126",
         "TomClancysGhostRecon",
         "Neutral",
         "It is not the first time that the EU Commission has taken such a step."
        ],
        [
         "67488",
         "7158",
         "johnson&johnson",
         "Negative",
         "Many boys and men who used the medication developed gynecomastia, or abnormal enlargement of the breasts. Thousands of lawsuits have been filed against manufacturer Janssen Pharmaceuticals and its parent company Johnson & Johnson regarding this severe side effect.. .  "
        ],
        [
         "50862",
         "6330",
         "FIFA",
         "Negative",
         "@EAHelp you rats really removed the option to record clips on fifa since your game is shit . "
        ],
        [
         "39856",
         "1242",
         "Battlefield",
         "Neutral",
         "Fair play I ’ m doing pretty shit on"
        ],
        [
         "54836",
         "2217",
         "CallOfDuty",
         "Negative",
         "People don't care."
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60062</th>\n",
       "      <td>3493</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>She is a. Want More? dirtibook.com.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72268</th>\n",
       "      <td>11181</td>\n",
       "      <td>TomClancysGhostRecon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>This punk thought he just was sneaky, he trapp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33483</th>\n",
       "      <td>6548</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>\"Fortnite BUT its best&lt;unk&gt; NOOBS\" youtube.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12569</th>\n",
       "      <td>8559</td>\n",
       "      <td>NBA2K</td>\n",
       "      <td>Positive</td>\n",
       "      <td>you would be the best addition 2k has ever rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56420</th>\n",
       "      <td>11282</td>\n",
       "      <td>TomClancysRainbowSix</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@ INTERRO Ik you probably don't care, but you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71959</th>\n",
       "      <td>11126</td>\n",
       "      <td>TomClancysGhostRecon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>It is not the first time that the EU Commissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67488</th>\n",
       "      <td>7158</td>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Many boys and men who used the medication deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50862</th>\n",
       "      <td>6330</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@EAHelp you rats really removed the option to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39856</th>\n",
       "      <td>1242</td>\n",
       "      <td>Battlefield</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Fair play I ’ m doing pretty shit on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54836</th>\n",
       "      <td>2217</td>\n",
       "      <td>CallOfDuty</td>\n",
       "      <td>Negative</td>\n",
       "      <td>People don't care.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                Entity   Sentiment  \\\n",
       "60062   3493              Facebook  Irrelevant   \n",
       "72268  11181  TomClancysGhostRecon     Neutral   \n",
       "33483   6548              Fortnite     Neutral   \n",
       "12569   8559                 NBA2K    Positive   \n",
       "56420  11282  TomClancysRainbowSix    Negative   \n",
       "71959  11126  TomClancysGhostRecon     Neutral   \n",
       "67488   7158       johnson&johnson    Negative   \n",
       "50862   6330                  FIFA    Negative   \n",
       "39856   1242           Battlefield     Neutral   \n",
       "54836   2217            CallOfDuty    Negative   \n",
       "\n",
       "                                                   Tweet  \n",
       "60062                She is a. Want More? dirtibook.com.  \n",
       "72268  This punk thought he just was sneaky, he trapp...  \n",
       "33483  \"Fortnite BUT its best<unk> NOOBS\" youtube.com...  \n",
       "12569  you would be the best addition 2k has ever rec...  \n",
       "56420  @ INTERRO Ik you probably don't care, but you ...  \n",
       "71959  It is not the first time that the EU Commissio...  \n",
       "67488  Many boys and men who used the medication deve...  \n",
       "50862  @EAHelp you rats really removed the option to ...  \n",
       "39856               Fair play I ’ m doing pretty shit on  \n",
       "54836                                 People don't care.  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Neutral     31308\n",
       "Negative    22542\n",
       "Positive    20832\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sentiment'] = train_df['Sentiment'].replace('Irrelevant', 'Neutral')\n",
    "\n",
    "train_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             0\n",
       "Entity         0\n",
       "Sentiment      0\n",
       "Tweet        686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Entity       0\n",
       "Sentiment    0\n",
       "Tweet        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.dropna(subset=['Tweet'])\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    text = text.lower()                                      # Lowercase\n",
    "    text = re.sub(r'@[\\w_]+', '', text)                      # Remove @mentions\n",
    "    text = re.sub(r'#\\w+', '', text)                         # Remove hashtags\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)              # Remove URLs\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)                          # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()                 # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Clean_Tweet",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ed716d27-d27b-4637-b33a-bde74dfcb9fc",
       "rows": [
        [
         "18809",
         "Months later I reinstalled version 3 to Check if the main menu still runs about 60 fps.. Some things never change. <unk>",
         "months later i reinstalled version to check if the main menu still runs about fps some things never change unk"
        ],
        [
         "12503",
         "Ayy or choc! Represent... @AEClan2K<unk> R",
         "ayy or choc represent unk r"
        ],
        [
         "10319",
         "Xbox Series with HD look: Fast, powerful and unparalleled performance.live/xbox-series-x-...",
         "xbox series with hd look fast powerful and unparalleled performancelivexboxseriesx"
        ],
        [
         "50721",
         "Dawggggg bernado silva beat my defender in the half n hacked me up. I cool",
         "dawggggg bernado silva beat my defender in the half n hacked me up i cool"
        ],
        [
         "70824",
         "@GhostRecon  ",
         ""
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Clean_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18809</th>\n",
       "      <td>Months later I reinstalled version 3 to Check ...</td>\n",
       "      <td>months later i reinstalled version to check if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>Ayy or choc! Represent... @AEClan2K&lt;unk&gt; R</td>\n",
       "      <td>ayy or choc represent unk r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10319</th>\n",
       "      <td>Xbox Series with HD look: Fast, powerful and u...</td>\n",
       "      <td>xbox series with hd look fast powerful and unp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50721</th>\n",
       "      <td>Dawggggg bernado silva beat my defender in the...</td>\n",
       "      <td>dawggggg bernado silva beat my defender in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70824</th>\n",
       "      <td>@GhostRecon</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  \\\n",
       "18809  Months later I reinstalled version 3 to Check ...   \n",
       "12503         Ayy or choc! Represent... @AEClan2K<unk> R   \n",
       "10319  Xbox Series with HD look: Fast, powerful and u...   \n",
       "50721  Dawggggg bernado silva beat my defender in the...   \n",
       "70824                                      @GhostRecon     \n",
       "\n",
       "                                             Clean_Tweet  \n",
       "18809  months later i reinstalled version to check if...  \n",
       "12503                        ayy or choc represent unk r  \n",
       "10319  xbox series with hd look fast powerful and unp...  \n",
       "50721  dawggggg bernado silva beat my defender in the...  \n",
       "70824                                                     "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Clean_Tweet'] = train_df['Tweet'].apply(clean_tweet)\n",
    "\n",
    "# Optional: Preview a few cleaned tweets\n",
    "train_df[['Tweet', 'Clean_Tweet']].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gnanreddybobba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Tweet",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Clean_Tweet",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ccb492a1-5ff3-4771-a952-0ca10904f650",
       "rows": [
        [
         "9334",
         "I might have to get an Xbox exclusive Series Five X just because because cheap of Fable. Please don'll t screw this up, save I'm hype...",
         "might get xbox exclusive series five x cheap fable please donll screw save im hype"
        ],
        [
         "52084",
         "And I finally have finished playing the original Red Dead Redemption after playing it straight on and pissed off for well over a new year and. It was so much so so good. I'm feeling a lot of things right now but it was really super good and I'm excited to get better 2",
         "finally finished playing original red dead redemption playing straight pissed well new year much good im feeling lot things right really super good im excited get better"
        ],
        [
         "11218",
         "Thank you.. Now focus on me making the one greatest game. please",
         "thank focus making one greatest game please"
        ],
        [
         "54528",
         "@Treyarch Call of Duty Black Ops 3 is the worst fucking game ever. The game is ruined by glitch class havin ass losers. Fix the fucking game. Can’t go into a single match without someone being invisible for a whole fucking round. Shit ass game, shit ass company  ",
         "call duty black ops worst fucking game ever game ruined glitch class havin ass losers fix fucking game can’t go single match without someone invisible whole fucking round shit ass game shit ass company"
        ],
        [
         "53361",
         "wrong. this good red dead redemption",
         "wrong good red dead redemption"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Clean_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>I might have to get an Xbox exclusive Series F...</td>\n",
       "      <td>might get xbox exclusive series five x cheap f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52084</th>\n",
       "      <td>And I finally have finished playing the origin...</td>\n",
       "      <td>finally finished playing original red dead red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11218</th>\n",
       "      <td>Thank you.. Now focus on me making the one gre...</td>\n",
       "      <td>thank focus making one greatest game please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54528</th>\n",
       "      <td>@Treyarch Call of Duty Black Ops 3 is the wors...</td>\n",
       "      <td>call duty black ops worst fucking game ever ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53361</th>\n",
       "      <td>wrong. this good red dead redemption</td>\n",
       "      <td>wrong good red dead redemption</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Tweet  \\\n",
       "9334   I might have to get an Xbox exclusive Series F...   \n",
       "52084  And I finally have finished playing the origin...   \n",
       "11218  Thank you.. Now focus on me making the one gre...   \n",
       "54528  @Treyarch Call of Duty Black Ops 3 is the wors...   \n",
       "53361               wrong. this good red dead redemption   \n",
       "\n",
       "                                             Clean_Tweet  \n",
       "9334   might get xbox exclusive series five x cheap f...  \n",
       "52084  finally finished playing original red dead red...  \n",
       "11218        thank focus making one greatest game please  \n",
       "54528  call duty black ops worst fucking game ever ga...  \n",
       "53361                     wrong good red dead redemption  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "train_df['Clean_Tweet'] = train_df['Clean_Tweet'].apply(remove_stopwords)\n",
    "# Optional: Preview a few cleaned tweets after stopword removal\n",
    "train_df[['Tweet', 'Clean_Tweet']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sentiment_Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sentiment_Label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Step 1: Define X and y\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClean_Tweet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m y \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment_Label\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Step 2: TF-IDF Vectorization\u001b[39;00m\n\u001b[1;32m      9\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Sentiment_Label'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Define X and y\n",
    "X = train_df['Clean_Tweet']\n",
    "y = train_df['Sentiment_Label']\n",
    "\n",
    "# Step 2: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 3: Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sentiment_Label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "87a7b128-79ae-43c5-8358-517a1a3c5d7d",
       "rows": [
        [
         "0",
         "Positive",
         "2"
        ],
        [
         "1",
         "Positive",
         "2"
        ],
        [
         "2",
         "Positive",
         "2"
        ],
        [
         "3",
         "Positive",
         "2"
        ],
        [
         "4",
         "Positive",
         "2"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Sentiment_Label\n",
       "0  Positive                2\n",
       "1  Positive                2\n",
       "2  Positive                2\n",
       "3  Positive                2\n",
       "4  Positive                2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map sentiment labels to numeric values\n",
    "label_map = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "train_df['Sentiment_Label'] = train_df['Sentiment'].map(label_map)\n",
    "\n",
    "# Verify the new column\n",
    "train_df[['Sentiment', 'Sentiment_Label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_df['Clean_Tweet']\n",
    "y = train_df['Sentiment_Label']\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6893918918918919\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70      4380\n",
      "           1       0.67      0.75      0.71      6301\n",
      "           2       0.70      0.61      0.65      4119\n",
      "\n",
      "    accuracy                           0.69     14800\n",
      "   macro avg       0.69      0.68      0.68     14800\n",
      "weighted avg       0.69      0.69      0.69     14800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2984 1081  315]\n",
      " [ 816 4720  765]\n",
      " [ 398 1222 2499]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7205405405405405\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.73      4380\n",
      "           1       0.71      0.76      0.73      6301\n",
      "           2       0.71      0.66      0.69      4119\n",
      "\n",
      "    accuracy                           0.72     14800\n",
      "   macro avg       0.72      0.71      0.72     14800\n",
      "weighted avg       0.72      0.72      0.72     14800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3151  925  304]\n",
      " [ 719 4795  787]\n",
      " [ 350 1051 2718]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# using logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize the model\n",
    "lr_model = LogisticRegression(max_iter=200)  # Increased max_iter just in case\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7333783783783784\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      4380\n",
      "           1       0.73      0.75      0.74      6301\n",
      "           2       0.72      0.69      0.70      4119\n",
      "\n",
      "    accuracy                           0.73     14800\n",
      "   macro avg       0.73      0.73      0.73     14800\n",
      "weighted avg       0.73      0.73      0.73     14800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3278  792  310]\n",
      " [ 739 4743  819]\n",
      " [ 331  955 2833]]\n"
     ]
    }
   ],
   "source": [
    "# using svm\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = LinearSVC()\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the trained SVM model\n",
    "joblib.dump(svm_model, 'svm_sentiment_model.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load later:\n",
    "model = joblib.load('svm_sentiment_model.pkl')\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Neutral\n",
      "Neutral\n",
      "Neutral\n",
      "Neutral\n",
      "Positive\n",
      "Neutral\n",
      "Neutral\n",
      "Neutral\n",
      "Positive\n",
      "Positive\n",
      "Neutral\n",
      "Neutral\n",
      "Neutral\n",
      "Positive\n",
      "Neutral\n",
      "Neutral\n",
      "Positive\n",
      "Neutral\n",
      "Neutral\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "def predict_sentiment(tweet):\n",
    "    # Clean the tweet\n",
    "    cleaned_tweet = clean_tweet(tweet)\n",
    "    \n",
    "    # Vectorize the tweet\n",
    "    vectorized_tweet = vectorizer.transform([cleaned_tweet])\n",
    "    \n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(vectorized_tweet)\n",
    "    \n",
    "    # Map back to original sentiment labels\n",
    "    sentiment_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "    \n",
    "    return sentiment_map[prediction[0]]\n",
    "# Test the function\n",
    "print(predict_sentiment(\"I love this product! It's amazing.\"))\n",
    "print(predict_sentiment(\"This is the worst experience I've ever had.\"))\n",
    "print(predict_sentiment(\"The service was okay, nothing special.\"))\n",
    "# Test with a tweet that contains a URL and mentions\n",
    "print(predict_sentiment(\"Check out this link: http://example.com @user\"))\n",
    "# Test with a tweet that contains numbers and punctuation\n",
    "print(predict_sentiment(\"I bought 2 tickets for the concert!!! Can't wait!\"))\n",
    "# Test with a tweet that contains emojis\n",
    "print(predict_sentiment(\"😊 This is so exciting! 🎉\"))\n",
    "# Test with a tweet that contains a hashtag\n",
    "print(predict_sentiment(\"I love #Python programming!\"))\n",
    "# Test with an empty tweet\n",
    "print(predict_sentiment(\"\"))\n",
    "# Test with a tweet that contains only stopwords\n",
    "print(predict_sentiment(\"is the in of to\"))\n",
    "# Test with a tweet that contains slang or abbreviations\n",
    "print(predict_sentiment(\"This is lit! Can't even!\"))\n",
    "# Test with a tweet that contains mixed languages\n",
    "print(predict_sentiment(\"Me encanta este producto! It's amazing.\"))\n",
    "# Test with a tweet that contains special characters\n",
    "print(predict_sentiment(\"I love this product! @#$%^&*()\"))\n",
    "# Test with a tweet that contains a mix of positive and negative sentiments\n",
    "print(predict_sentiment(\"I love this product, but the service was terrible.\"))\n",
    "# Test with a tweet that contains sarcasm\n",
    "print(predict_sentiment(\"Oh great, another product that doesn't work.\"))\n",
    "# Test with a tweet that contains a question\n",
    "print(predict_sentiment(\"Is this product really as good as they say?\"))\n",
    "# Test with a tweet that contains a quote\n",
    "print(predict_sentiment(\"As Shakespeare said, 'All the world's a stage.'\"))\n",
    "# Test with a tweet that contains a call to action\n",
    "print(predict_sentiment(\"Check out this amazing product! You won't regret it.\"))\n",
    "# Test with a tweet that contains a review\n",
    "print(predict_sentiment(\"This product is fantastic! I highly recommend it.\"))\n",
    "# Test with a tweet that contains a complaint\n",
    "print(predict_sentiment(\"I'm really disappointed with this product.\"))\n",
    "# Test with a tweet that contains a compliment\n",
    "print(predict_sentiment(\"This is the best product I've ever used!\"))\n",
    "# Test with a tweet that contains a suggestion\n",
    "print(predict_sentiment(\"I think they should improve the packaging.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
